{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../data/*.csv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path('../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH/'train.csv')[::10]\n",
    "test = pd.read_csv(PATH/'test.csv')[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_atomtype(df, s):\n",
    "    # https://www.kaggle.com/jazivxt/all-this-over-a-dog\n",
    "    df['atom1'] = df['type'].map(lambda x: str(x)[2])\n",
    "    df['atom2'] = df['type'].map(lambda x: str(x)[3])\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    for i in range(4):\n",
    "        df['type'+str(i)] = lbl.fit_transform(df['type'].map(lambda x: str(x)[i]))\n",
    "\n",
    "    df = pd.merge(df, s.rename(columns={'atom_index':'atom_index_0', 'x':'x0', 'y':'y0', 'z':'z0', 'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "    df = pd.merge(df, s.rename(columns={'atom_index':'atom_index_1', 'x':'x1', 'y':'y1', 'z':'z1', 'atom':'atom2'}), how='left', on=['molecule_name', 'atom_index_1', 'atom2'])\n",
    "    return df\n",
    "\n",
    "def feature_pair_geometry(df):\n",
    "    p0 = df[['x0', 'y0', 'z0']].values\n",
    "    p1 = df[['x1', 'y1', 'z1']].values\n",
    "    r = np.linalg.norm(p0 - p1, axis=1)\n",
    "    df['dist'] = r\n",
    "\n",
    "    for agg in ['min', 'max', 'mean']:\n",
    "        tmp = eval('df.groupby([\"type\"], as_index=False).dist.' + agg + '()')\n",
    "        tmp.rename(columns={\"dist\":agg + \"_dist\"}, inplace=True)\n",
    "        df = pd.merge(df, tmp, how='left', on=['type'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    # somewhere from kaggle kernel\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem)\n",
    " / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_basic(df):\n",
    "    structures = pd.read_csv(PATH/'structures.csv')\n",
    "    df = feature_atomtype(df, structures)\n",
    "    df = feature_pair_geometry(df)\n",
    "    df = reduce_mem_usage(df)\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 41.76 Mb (48.9% reduction)\n",
      "Mem. usage decreased to 21.51 Mb (48.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = feature_basic(train)\n",
    "test = feature_basic(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom1</th>\n",
       "      <th>atom2</th>\n",
       "      <th>type0</th>\n",
       "      <th>type1</th>\n",
       "      <th>...</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>z0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>dist</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>mean_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>1.061272</td>\n",
       "      <td>1.121432</td>\n",
       "      <td>1.092919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>dsgdb9nsd_000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHN</td>\n",
       "      <td>32.688900</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>1.083587</td>\n",
       "      <td>1.012903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "      <td>-2.378310</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994873</td>\n",
       "      <td>1.939743</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>2.182492</td>\n",
       "      <td>1.831791</td>\n",
       "      <td>2.520050</td>\n",
       "      <td>2.190124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3JHH</td>\n",
       "      <td>3.252530</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542076</td>\n",
       "      <td>1.923611</td>\n",
       "      <td>-0.865117</td>\n",
       "      <td>-1.011477</td>\n",
       "      <td>-0.418034</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>2.543345</td>\n",
       "      <td>2.077450</td>\n",
       "      <td>3.165045</td>\n",
       "      <td>2.703366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.699300</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>-0.401908</td>\n",
       "      <td>0.877544</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>-0.392470</td>\n",
       "      <td>-0.887601</td>\n",
       "      <td>1.765251</td>\n",
       "      <td>1.606630</td>\n",
       "      <td>1.969340</td>\n",
       "      <td>1.774909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1  10  dsgdb9nsd_000002             1             0  1JHN   \n",
       "2  20  dsgdb9nsd_000007             2             1  2JHC   \n",
       "3  30  dsgdb9nsd_000007             3             6  3JHH   \n",
       "4  40  dsgdb9nsd_000007             5             7  2JHH   \n",
       "\n",
       "   scalar_coupling_constant atom1 atom2  type0  type1    ...            x0  \\\n",
       "0                 84.807602     H     C      0      0    ...      0.002150   \n",
       "1                 32.688900     H     N      0      0    ...      0.017257   \n",
       "2                 -2.378310     H     C      1      0    ...      0.994873   \n",
       "3                  3.252530     H     H      2      0    ...     -0.542076   \n",
       "4                -11.699300     H     H      1      0    ...      0.525487   \n",
       "\n",
       "         y0        z0        x1        y1        z1      dist  min_dist  \\\n",
       "0 -0.006031  0.001976 -0.012698  1.085804  0.008001  1.091953  1.061272   \n",
       "1  0.012545 -0.027377 -0.040426  1.024108  0.062564  1.017190  1.002405   \n",
       "2  1.939743  0.002941  0.002104 -0.003882  0.001999  2.182492  1.831791   \n",
       "3  1.923611 -0.865117 -1.011477 -0.418034  0.009508  2.543345  2.077450   \n",
       "4 -0.401908  0.877544  0.508626 -0.392470 -0.887601  1.765251  1.606630   \n",
       "\n",
       "   max_dist  mean_dist  \n",
       "0  1.121432   1.092919  \n",
       "1  1.083587   1.012903  \n",
       "2  2.520050   2.190124  \n",
       "3  3.165045   2.703366  \n",
       "4  1.969340   1.774909  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/adrianoavelar/bond-calculaltion-lb-0-82\n",
    "def feature_neighbors(s):\n",
    "    i_atom = s['atom_index'].values\n",
    "    i_atom_type = s['atom'].values\n",
    "    p = s[['x', 'y', 'z']].values\n",
    "    m = s['molecule_name'].values\n",
    "    t = np.empty((len(s)+1), dtype=np.object)\n",
    "    t[:len(s)] = s['atom'].values\n",
    "    p_compare = p\n",
    "    m_compare = m\n",
    "    t_compare = t\n",
    "    source_row = np.arange(len(s))\n",
    "    max_atoms = max(s.groupby('molecule_name').atom_index.max().values)\n",
    "    bonds = np.zeros((len(s)+1, max_atoms+1), dtype=np.int8)\n",
    "    bond_dists = np.zeros((len(s)+1, max_atoms+1), dtype=np.float32)\n",
    "    bond_atoms = np.empty((len(s)+1, max_atoms+1), dtype=np.object)\n",
    "    for i in tqdm(range(max_atoms-1)):\n",
    "        p_compare = np.roll(p_compare, -1, axis=0)\n",
    "        m_compare = np.roll(m_compare, -1, axis=0)\n",
    "        t_compare = np.roll(t_compare, -1, axis=0)\n",
    "\n",
    "        mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n",
    "        dists = np.linalg.norm(p - p_compare, axis=1) * mask\n",
    "        r_bond = 3.0\n",
    "\n",
    "        bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n",
    "\n",
    "        source_row = source_row\n",
    "        target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_row = np.where(np.logical_or(target_row > len(s), mask==0), len(s), target_row) #If invalid target, write to dummy row\n",
    "\n",
    "        source_atom = i_atom\n",
    "        target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n",
    "\n",
    "        target_atom_type = np.where(np.logical_or(target_row > len(s), mask==0), '', t[target_row]) #If invalid target, write to dummy row    \n",
    "        source_atom_type = i_atom_type\n",
    "\n",
    "        bonds[(source_row, target_atom)] = bond\n",
    "        bonds[(target_row, source_atom)] = bond\n",
    "        bond_dists[(source_row, target_atom)] = dists\n",
    "        bond_dists[(target_row, source_atom)] = dists\n",
    "        bond_atoms[(source_row, target_atom)] = target_atom_type\n",
    "        bond_atoms[(target_row, source_atom)] = source_atom_type\n",
    "\n",
    "    bonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\n",
    "    bonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\n",
    "    bond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\n",
    "    bond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n",
    "    bond_atoms = np.delete(bond_atoms, axis=0, obj=-1) #Delete dummy row\n",
    "    bond_atoms = np.delete(bond_atoms, axis=1, obj=-1) #Delete dummy col\n",
    "    \n",
    "    mask = bonds == 1\n",
    "    bond_lengths_mean = [np.mean(row[mask[j]]) for j,row in enumerate(tqdm(bond_dists))]\n",
    "    n_bonds = np.sum(bonds, axis=1)\n",
    "    bond_data = {'n_bonds':n_bonds, 'bond_lengths_mean': bond_lengths_mean }\n",
    "    bond_df = pd.DataFrame(bond_data)\n",
    "    s = s.join(bond_df)\n",
    "    \n",
    "    atom_types = ['C', 'N', 'H', 'O', 'F']\n",
    "    bond_data = {}\n",
    "    for at in atom_types:\n",
    "        bonds_at = np.empty((len(s), max_atoms), dtype=np.int8) \n",
    "        bonds_at[:] = -1\n",
    "        for i in tqdm(range(len(bond_atoms))):\n",
    "            mask = bond_atoms[i,:] == at\n",
    "            atom_j_indices = np.argwhere(mask)\n",
    "            dists = bond_dists[i, mask]\n",
    "            atom_j_sorted = np.argsort(dists)\n",
    "            bonds_at[i, :len(atom_j_sorted)] = atom_j_sorted\n",
    "            \n",
    "        maxatom = np.max(np.sum(bonds_at >= 0, axis=1))\n",
    "        for i in range(maxatom):\n",
    "            bond_data['bond_%s_%d' % (at, i)] = bonds_at[:, i]\n",
    "    bond_df = pd.DataFrame(bond_data)\n",
    "    s = s.join(bond_df)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bonds(df1, df2):\n",
    "    structures = pd.read_csv(PATH/'structures.csv')\n",
    "    structures = feature_neighbors(structures)\n",
    "    df1 = pd.merge(df1, structures.drop(['x', 'y', 'z'], axis=1).rename(columns={'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "    df1 = pd.merge(df1, structures.drop(['x', 'y', 'z'], axis=1).rename(columns={'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "    df2 = pd.merge(df2, structures.drop(['x', 'y', 'z'], axis=1).rename(columns={'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "    df2 = pd.merge(df2, structures.drop(['x', 'y', 'z'], axis=1).rename(columns={'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "\n",
    "    df1 = reduce_mem_usage(df1)\n",
    "    df2 = reduce_mem_usage(df2)\n",
    "    gc.collect()\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:07<00:00,  3.72it/s]\n",
      "100%|██████████| 2358657/2358657 [00:18<00:00, 127733.39it/s]\n",
      "100%|██████████| 2358657/2358657 [00:25<00:00, 91266.23it/s]\n",
      " 44%|████▍     | 1048253/2358657 [00:11<00:14, 93139.25it/s]"
     ]
    }
   ],
   "source": [
    "train, test = feature_bonds(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'atom1', 'atom2'] + ['x0', 'y0', 'z0', 'x1', 'y1', 'z1']\n",
    "col = [c for c in train.columns if c not in ['scalar_coupling_constant'] + excluded]\n",
    "reg = ensemble.ExtraTreesRegressor(n_jobs=-1, n_estimators=20, random_state=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
       "       'scalar_coupling_constant', 'atom1', 'atom2', 'type0', 'type1',\n",
       "       ...\n",
       "       'bond_O_1_y', 'bond_O_2_y', 'bond_O_3_y', 'bond_O_4_y', 'bond_F_0_y',\n",
       "       'bond_F_1_y', 'bond_F_2_y', 'bond_F_3_y', 'bond_F_4_y', 'bond_F_5_y'],\n",
       "      dtype='object', length=124)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train[col], train['scalar_coupling_constant'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   38.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,\n",
       "          oob_score=False, random_state=4, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train.drop(['type'], axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/uberkinder/efficient-metric\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test.drop('type', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23199779434054785"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mean_log_mae(y_test, y_pred, X_test.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC 3.13440698398015\n",
      "1JHN 1.8348052993434065\n",
      "2JHC 1.61181149884822\n",
      "3JHH 0.9873188273634053\n",
      "2JHH 0.7384456583758383\n",
      "3JHC 1.5267124508881924\n",
      "2JHN 1.047342654303434\n",
      "3JHN 0.592053938633429\n"
     ]
    }
   ],
   "source": [
    "for t in train.type.unique():\n",
    "    idx = X_test.type == t\n",
    "    print(t, (y_test[idx] - y_pred[idx]).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunhwan/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,\n",
       "          oob_score=False, random_state=4, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with all data\n",
    "reg.fit(train[col].drop('type', axis=1), train['scalar_coupling_constant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "test['scalar_coupling_constant']  = reg.predict(test[col].drop('type', axis=1))\n",
    "test[['id', 'scalar_coupling_constant']].to_csv('submission.csv', index=False) #float_format='%.9f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/sunhwan/work/kaggle/champs-scalar-coupling/nbs/submission.csv"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score: ~0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
