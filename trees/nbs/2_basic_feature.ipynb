{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/1_average_coupling.csv\r\n",
      "../data/dipole_moments.csv\r\n",
      "../data/magnetic_shielding_tensors.csv\r\n",
      "../data/mulliken_charges.csv\r\n",
      "../data/potential_energy.csv\r\n",
      "../data/sample_submission.csv\r\n",
      "../data/scalar_coupling_contributions.csv\r\n",
      "../data/structures.csv\r\n",
      "../data/test_4_more_features.csv\r\n",
      "../data/test_7_coupling_constant.csv\r\n",
      "../data/test.csv\r\n",
      "../data/test_tmp.csv\r\n",
      "../data/train_4_more_features.csv\r\n",
      "../data/train_7_coupling_constant.csv\r\n",
      "../data/train.csv\r\n",
      "../data/train_tmp.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH/'train.csv')[::10]\n",
    "test = pd.read_csv(PATH/'test.csv')[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_atomtype(df, s):\n",
    "    # https://www.kaggle.com/jazivxt/all-this-over-a-dog\n",
    "    df['atom1'] = df['type'].map(lambda x: str(x)[2])\n",
    "    df['atom2'] = df['type'].map(lambda x: str(x)[3])\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    for i in range(4):\n",
    "        df['type'+str(i)] = lbl.fit_transform(df['type'].map(lambda x: str(x)[i]))\n",
    "\n",
    "    df = pd.merge(df, s.rename(columns={'atom_index':'atom_index_0', 'x':'x0', 'y':'y0', 'z':'z0', 'atom':'atom1'}), how='left', on=['molecule_name', 'atom_index_0', 'atom1'])\n",
    "    df = pd.merge(df, s.rename(columns={'atom_index':'atom_index_1', 'x':'x1', 'y':'y1', 'z':'z1', 'atom':'atom2'}), how='left', on=['molecule_name', 'atom_index_1', 'atom2'])\n",
    "    return df\n",
    "\n",
    "def feature_pair_geometry(df):\n",
    "    p0 = df[['x0', 'y0', 'z0']].values\n",
    "    p1 = df[['x1', 'y1', 'z1']].values\n",
    "    r = np.linalg.norm(p0 - p1, axis=1)\n",
    "    df['dist'] = r\n",
    "\n",
    "    for agg in ['min', 'max', 'mean']:\n",
    "        tmp = eval('df.groupby([\"type\"], as_index=False).dist.' + agg + '()')\n",
    "        tmp.rename(columns={\"dist\":agg + \"_dist\"}, inplace=True)\n",
    "        df = pd.merge(df, tmp, how='left', on=['type'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    # somewhere from kaggle kernel\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem)\n",
    " / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_basic(df):\n",
    "    structures = pd.read_csv(PATH/'structures.csv')\n",
    "    df = feature_atomtype(df, structures)\n",
    "    df = feature_pair_geometry(df)\n",
    "    df = reduce_mem_usage(df)\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 31.98 Mb (60.9% reduction)\n",
      "Mem. usage decreased to 16.73 Mb (60.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = feature_basic(train)\n",
    "test = feature_basic(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'atom1', 'atom2'] + ['x0', 'y0', 'z0', 'x1', 'y1', 'z1']\n",
    "col = [c for c in train.columns if c not in ['scalar_coupling_constant'] + excluded]\n",
    "reg = ensemble.ExtraTreesRegressor(n_jobs=-1, n_estimators=20, random_state=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'type0',\n",
       " 'type1',\n",
       " 'type2',\n",
       " 'type3',\n",
       " 'dist',\n",
       " 'min_dist',\n",
       " 'max_dist',\n",
       " 'mean_dist']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(train[col], train['scalar_coupling_constant'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunhwan/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,\n",
       "          oob_score=False, random_state=4, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train.drop(['type'], axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/uberkinder/efficient-metric\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test.drop('type', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587598234024385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mean_log_mae(y_test, y_pred, X_test.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC 5.268634709340875\n",
      "1JHN 2.921645829396459\n",
      "2JHC 2.502172447427435\n",
      "3JHH 1.8745136356193908\n",
      "2JHH 1.3325881808233813\n",
      "3JHC 2.093548698203321\n",
      "2JHN 2.504358464326092\n",
      "3JHN 0.8578169430747304\n"
     ]
    }
   ],
   "source": [
    "for t in train.type.unique():\n",
    "    idx = X_test.type == t\n",
    "    print(t, (y_test[idx] - y_pred[idx]).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunhwan/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=-1,\n",
       "          oob_score=False, random_state=4, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with all data\n",
    "reg.fit(train[col].drop('type', axis=1), train['scalar_coupling_constant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "test['scalar_coupling_constant']  = reg.predict(test[col].drop('type', axis=1))\n",
    "test[['id', 'scalar_coupling_constant']].to_csv('submission.csv', index=False) #float_format='%.9f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/sunhwan/work/kaggle/champs-scalar-coupling/nbs/submission.csv"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score: ~0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
